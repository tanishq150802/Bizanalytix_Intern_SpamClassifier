{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spam_classifier",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanishq150802/Bizanalytix_Intern_SpamClassifier/blob/main/spam_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fetching the data**"
      ],
      "metadata": {
        "id": "k9cDa3nSl6-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "import urllib\n",
        "import os\n",
        "import urllib.request\n",
        "\n",
        "DOWNLOAD_ROOT = \"http://spamassassin.apache.org/old/publiccorpus/\"\n",
        "HAM_URL = DOWNLOAD_ROOT + \"20030228_easy_ham.tar.bz2\"\n",
        "SPAM_URL = DOWNLOAD_ROOT + \"20030228_spam.tar.bz2\"\n",
        "SPAM_PATH = os.path.join(\"datasets\", \"spam\")\n",
        "\n",
        "def fetch_data(spam_url=SPAM_URL, spam_path=SPAM_PATH):\n",
        "    if not os.path.isdir(spam_path):\n",
        "        os.makedirs(spam_path)\n",
        "    for filename, url in ((\"ham.tar.bz2\", HAM_URL), (\"spam.tar.bz2\", SPAM_URL)):\n",
        "        path = os.path.join(spam_path, filename)\n",
        "        if not os.path.isfile(path):\n",
        "            urllib.request.urlretrieve(url, path)\n",
        "        tar_bz2_file = tarfile.open(path)\n",
        "        tar_bz2_file.extractall(path=SPAM_PATH)\n",
        "        tar_bz2_file.close()\n",
        "\n",
        "fetch_data()"
      ],
      "metadata": {
        "id": "9Tc1t8u59hcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading emails having name length greater than 21**"
      ],
      "metadata": {
        "id": "DBZtOBmpn8MY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HAM_DIR = os.path.join(SPAM_PATH, \"easy_ham\")\n",
        "SPAM_DIR = os.path.join(SPAM_PATH, \"spam\")\n",
        "ham_filenames = [name for name in sorted(os.listdir(HAM_DIR)) if len(name) > 21]\n",
        "spam_filenames = [name for name in sorted(os.listdir(SPAM_DIR)) if len(name) > 21]\n",
        "\n",
        "print(len(ham_filenames),len(spam_filenames))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAHVmjo59z6w",
        "outputId": "8861bd6c-7789-42cd-a703-82f5be05f835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parsing emails using email library (I thank Vikram sir for helping)**"
      ],
      "metadata": {
        "id": "jrPui2vboU12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import email\n",
        "import email.policy\n",
        "\n",
        "def load_email(is_spam, filename, spam_path=SPAM_PATH):\n",
        "    directory = \"spam\" if is_spam else \"easy_ham\"\n",
        "    with open(os.path.join(spam_path, directory, filename), \"rb\") as f:\n",
        "        return email.parser.BytesParser(policy=email.policy.default).parse(f)\n",
        "\n",
        "ham_emails = [load_email(is_spam=False, filename=name) for name in ham_filenames]\n",
        "spam_emails = [load_email(is_spam=True, filename=name) for name in spam_filenames]"
      ],
      "metadata": {
        "id": "-q22zthI9_RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Printing few examples**"
      ],
      "metadata": {
        "id": "256TZDyFonLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(ham_emails[0].get_content().strip())\n",
        "print(spam_emails[0].get_content().strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUcy5EOn-Id7",
        "outputId": "49e00bef-785f-4cfd-e615-6231bdc40e5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date:        Wed, 21 Aug 2002 10:54:46 -0500\n",
            "    From:        Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>\n",
            "    Message-ID:  <1029945287.4797.TMDA@deepeddy.vircio.com>\n",
            "\n",
            "\n",
            "  | I can't reproduce this error.\n",
            "\n",
            "For me it is very repeatable... (like every time, without fail).\n",
            "\n",
            "This is the debug log of the pick happening ...\n",
            "\n",
            "18:19:03 Pick_It {exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace} {4852-4852 -sequence mercury}\n",
            "18:19:03 exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace 4852-4852 -sequence mercury\n",
            "18:19:04 Ftoc_PickMsgs {{1 hit}}\n",
            "18:19:04 Marking 1 hits\n",
            "18:19:04 tkerror: syntax error in expression \"int ...\n",
            "\n",
            "Note, if I run the pick command by hand ...\n",
            "\n",
            "delta$ pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace  4852-4852 -sequence mercury\n",
            "1 hit\n",
            "\n",
            "That's where the \"1 hit\" comes from (obviously).  The version of nmh I'm\n",
            "using is ...\n",
            "\n",
            "delta$ pick -version\n",
            "pick -- nmh-1.0.4 [compiled on fuchsia.cs.mu.OZ.AU at Sun Mar 17 14:55:56 ICT 2002]\n",
            "\n",
            "And the relevant part of my .mh_profile ...\n",
            "\n",
            "delta$ mhparam pick\n",
            "-seq sel -list\n",
            "\n",
            "\n",
            "Since the pick command works, the sequence (actually, both of them, the\n",
            "one that's explicit on the command line, from the search popup, and the\n",
            "one that comes from .mh_profile) do get created.\n",
            "\n",
            "kre\n",
            "\n",
            "ps: this is still using the version of the code form a day ago, I haven't\n",
            "been able to reach the cvs repository today (local routing issue I think).\n",
            "\n",
            "\n",
            "\n",
            "_______________________________________________\n",
            "Exmh-workers mailing list\n",
            "Exmh-workers@redhat.com\n",
            "https://listman.redhat.com/mailman/listinfo/exmh-workers\n",
            "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">\n",
            "<HTML><HEAD>\n",
            "<META content=\"text/html; charset=windows-1252\" http-equiv=Content-Type>\n",
            "<META content=\"MSHTML 5.00.2314.1000\" name=GENERATOR></HEAD>\n",
            "<BODY><!-- Inserted by Calypso -->\n",
            "<TABLE border=0 cellPadding=0 cellSpacing=2 id=_CalyPrintHeader_ rules=none \n",
            "style=\"COLOR: black; DISPLAY: none\" width=\"100%\">\n",
            "  <TBODY>\n",
            "  <TR>\n",
            "    <TD colSpan=3>\n",
            "      <HR color=black noShade SIZE=1>\n",
            "    </TD></TR></TD></TR>\n",
            "  <TR>\n",
            "    <TD colSpan=3>\n",
            "      <HR color=black noShade SIZE=1>\n",
            "    </TD></TR></TBODY></TABLE><!-- End Calypso --><!-- Inserted by Calypso --><FONT \n",
            "color=#000000 face=VERDANA,ARIAL,HELVETICA size=-2><BR></FONT></TD></TR></TABLE><!-- End Calypso --><FONT color=#ff0000 \n",
            "face=\"Copperplate Gothic Bold\" size=5 PTSIZE=\"10\">\n",
            "<CENTER>Save up to 70% on Life Insurance.</CENTER></FONT><FONT color=#ff0000 \n",
            "face=\"Copperplate Gothic Bold\" size=5 PTSIZE=\"10\">\n",
            "<CENTER>Why Spend More Than You Have To?\n",
            "<CENTER><FONT color=#ff0000 face=\"Copperplate Gothic Bold\" size=5 PTSIZE=\"10\">\n",
            "<CENTER>Life Quote Savings\n",
            "<CENTER>\n",
            "<P align=left></P>\n",
            "<P align=left></P></FONT></U></I></B><BR></FONT></U></B></U></I>\n",
            "<P></P>\n",
            "<CENTER>\n",
            "<TABLE border=0 borderColor=#111111 cellPadding=0 cellSpacing=0 width=650>\n",
            "  <TBODY></TBODY></TABLE>\n",
            "<TABLE border=0 borderColor=#111111 cellPadding=5 cellSpacing=0 width=650>\n",
            "  <TBODY>\n",
            "  <TR>\n",
            "    <TD colSpan=2 width=\"35%\"><B><FONT face=Verdana size=4>Ensuring your \n",
            "      family's financial security is very important. Life Quote Savings makes \n",
            "      buying life insurance simple and affordable. We Provide FREE Access to The \n",
            "      Very Best Companies and The Lowest Rates.</FONT></B></TD></TR>\n",
            "  <TR>\n",
            "    <TD align=middle vAlign=top width=\"18%\">\n",
            "      <TABLE borderColor=#111111 width=\"100%\">\n",
            "        <TBODY>\n",
            "        <TR>\n",
            "          <TD style=\"PADDING-LEFT: 5px; PADDING-RIGHT: 5px\" width=\"100%\"><FONT \n",
            "            face=Verdana size=4><B>Life Quote Savings</B> is FAST, EASY and \n",
            "            SAVES you money! Let us help you get started with the best values in \n",
            "            the country on new coverage. You can SAVE hundreds or even thousands \n",
            "            of dollars by requesting a FREE quote from Lifequote Savings. Our \n",
            "            service will take you less than 5 minutes to complete. Shop and \n",
            "            compare. SAVE up to 70% on all types of Life insurance! \n",
            "</FONT></TD></TR>\n",
            "        <TR><BR><BR>\n",
            "          <TD height=50 style=\"PADDING-LEFT: 5px; PADDING-RIGHT: 5px\" \n",
            "          width=\"100%\">\n",
            "            <P align=center><B><FONT face=Verdana size=5><A \n",
            "            href=\"http://website.e365.cc/savequote/\">Click Here For Your \n",
            "            Free Quote!</A></FONT></B></P></TD>\n",
            "          <P><FONT face=Verdana size=4><STRONG>\n",
            "          <CENTER>Protecting your family is the best investment you'll ever \n",
            "          make!<BR></B></TD></TR>\n",
            "        <TR><BR><BR></STRONG></FONT></TD></TR></TD></TR>\n",
            "        <TR></TR></TBODY></TABLE>\n",
            "      <P align=left><FONT face=\"Arial, Helvetica, sans-serif\" size=2></FONT></P>\n",
            "      <P></P>\n",
            "      <CENTER><BR><BR><BR>\n",
            "      <P></P>\n",
            "      <P align=left><BR></B><BR><BR><BR><BR></P>\n",
            "      <P align=center><BR></P>\n",
            "      <P align=left><BR></B><BR><BR></FONT>If you are in receipt of this email \n",
            "      in error and/or wish to be removed from our list, <A \n",
            "      href=\"mailto:coins@btamail.net.cn\">PLEASE CLICK HERE</A> AND TYPE REMOVE. If you \n",
            "      reside in any state which prohibits e-mail solicitations for insurance, \n",
            "      please disregard this \n",
            "      email.<BR></FONT><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR></FONT></P></CENTER></CENTER></TR></TBODY></TABLE></CENTER></CENTER></CENTER></CENTER></CENTER></BODY></HTML>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**counting different email structures like Multipart/plain**"
      ],
      "metadata": {
        "id": "d6A9J6N-p3R5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_email_structure(email):\n",
        "    if isinstance(email, str): #if the mail has just strings then it may be mostly plain\n",
        "        return email\n",
        "    payload = email.get_payload()\n",
        "    if isinstance(payload, list): #otherwise if its a list then it may be multipart\n",
        "        return \"multipart({})\".format(\", \".join([\n",
        "            get_email_structure(sub_email)\n",
        "            for sub_email in payload]))\n",
        "    else:\n",
        "        return email.get_content_type()\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def structures_counter(emails):\n",
        "    structures = Counter()\n",
        "    for email in emails:\n",
        "        struc = get_email_structure(email)\n",
        "        structures[struc] = structures[struc]+1\n",
        "    return structures\n",
        "\n",
        "structures_counter(ham_emails).most_common()\n",
        "\n",
        "structures_counter(spam_emails).most_common()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pIp7Le4-WMd",
        "outputId": "525d7ba3-9086-4ba8-db30-d55c18ac6e55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('text/plain', 218),\n",
              " ('text/html', 183),\n",
              " ('multipart(text/plain, text/html)', 45),\n",
              " ('multipart(text/html)', 20),\n",
              " ('multipart(text/plain)', 19),\n",
              " ('multipart(multipart(text/html))', 5),\n",
              " ('multipart(text/plain, image/jpeg)', 3),\n",
              " ('multipart(text/html, application/octet-stream)', 2),\n",
              " ('multipart(text/plain, application/octet-stream)', 1),\n",
              " ('multipart(text/html, text/plain)', 1),\n",
              " ('multipart(multipart(text/html), application/octet-stream, image/jpeg)', 1),\n",
              " ('multipart(multipart(text/plain, text/html), image/gif)', 1),\n",
              " ('multipart/alternative', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Taking a look at one of the email header**"
      ],
      "metadata": {
        "id": "E7j4LOsgrRdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for header, value in spam_emails[1].items(): \n",
        "    print(header,\":\",value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQXTK5_X-nQm",
        "outputId": "f5ae5c9f-58e9-490e-f159-9e91e38230b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Return-Path : <ilug-admin@linux.ie>\n",
            "Delivered-To : zzzz@localhost.spamassassin.taint.org\n",
            "Received : from localhost (localhost [127.0.0.1])\tby phobos.labs.spamassassin.taint.org (Postfix) with ESMTP id A7FD7454F6\tfor <zzzz@localhost>; Thu, 22 Aug 2002 08:27:38 -0400 (EDT)\n",
            "Received : from phobos [127.0.0.1]\tby localhost with IMAP (fetchmail-5.9.0)\tfor zzzz@localhost (single-drop); Thu, 22 Aug 2002 13:27:38 +0100 (IST)\n",
            "Received : from lugh.tuatha.org (root@lugh.tuatha.org [194.125.145.45]) by    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g7MCJiZ06043 for    <zzzz-ilug@jmason.org>; Thu, 22 Aug 2002 13:19:44 +0100\n",
            "Received : from lugh (root@localhost [127.0.0.1]) by lugh.tuatha.org    (8.9.3/8.9.3) with ESMTP id NAA29323; Thu, 22 Aug 2002 13:18:52 +0100\n",
            "Received : from email.qves.com ([67.104.83.251]) by lugh.tuatha.org    (8.9.3/8.9.3) with ESMTP id NAA29282 for <ilug@linux.ie>; Thu,    22 Aug 2002 13:18:37 +0100\n",
            "X-Authentication-Warning : lugh.tuatha.org: Host [67.104.83.251] claimed to    be email.qves.com\n",
            "Received : from qvp0091 ([169.254.6.22]) by email.qves.com with Microsoft    SMTPSVC(5.0.2195.2966); Thu, 22 Aug 2002 06:18:18 -0600\n",
            "From : Slim Down <taylor@s3.serveimage.com>\n",
            "To : ilug@linux.ie\n",
            "Date : Thu, 22 Aug 2002 06:18:18 -0600\n",
            "Message-Id : <59e6301c249d5$ffb7ea20$1606fea9@freeyankeedom.com>\n",
            "MIME-Version : 1.0\n",
            "Content-Type : text/plain; charset=\"iso-8859-1\"\n",
            "Content-Transfer-Encoding : 7bit\n",
            "X-Mailer : Microsoft CDO for Windows 2000\n",
            "Thread-Index : AcJJ1f+3FWdz11AmR6uWbmQN5gGxxw==\n",
            "Content-Class : urn:content-classes:message\n",
            "X-Mimeole : Produced By Microsoft MimeOLE V6.00.2462.0000\n",
            "X-Originalarrivaltime : 22 Aug 2002 12:18:18.0699 (UTC) FILETIME=[FFB949B0:01C249D5]\n",
            "Subject : [ILUG] Guaranteed to lose 10-12 lbs in 30 days 10.206\n",
            "Sender : ilug-admin@linux.ie\n",
            "Errors-To : ilug-admin@linux.ie\n",
            "X-Mailman-Version : 1.1\n",
            "Precedence : bulk\n",
            "List-Id : Irish Linux Users' Group <ilug.linux.ie>\n",
            "X-Beenthere : ilug@linux.ie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spam_emails[1][\"Subject\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "awosl87V-tHb",
        "outputId": "b430f74a-4f93-460e-b67f-f3719e7bbe55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[ILUG] Guaranteed to lose 10-12 lbs in 30 days 10.206'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**70-30 Train-Test Split**"
      ],
      "metadata": {
        "id": "8d2TYF3Br2CK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = np.array(ham_emails + spam_emails)\n",
        "y = np.array([0] * len(ham_emails) + [1] * len(spam_emails))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZVllY9R-8H_",
        "outputId": "0eae2dc1-3c86-4a17-8cf6-4c188dec2097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HTML to plain text function (No use of BeautifulSoup)**"
      ],
      "metadata": {
        "id": "ILw1_RiQs0E4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from html import unescape\n",
        "def html_to_plain_text(html):\n",
        "    text = re.sub('<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I)\n",
        "    text = re.sub('<a\\s.*?>', ' HYPERLINK ', text, flags=re.M | re.S | re.I)\n",
        "    text = re.sub('<.*?>', '', text, flags=re.M | re.S)\n",
        "    text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S)\n",
        "    return unescape(text)\n",
        "\n",
        "html_spam_emails = [email for email in X_train[y_train==1] if get_email_structure(email) == \"text/html\"]\n",
        "sample_html_spam = html_spam_emails[0]\n",
        "\n",
        "print(sample_html_spam.get_content().strip()[:1000], \"...\") \n",
        "print(html_to_plain_text(sample_html_spam.get_content())[:1000], \"...\") #printing a converted example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioVttoko_TbF",
        "outputId": "8ac4852c-edae-4a3b-d622-31ed82d51f92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<HTML><TABLE WIDTH=100% BORDER=0 CELLPADDING=0 CELLSPACING=0><TR><TD align=center valign=middle BGCOLOR=#0A0A5A><center><a href=http://www.freepornsecrets.net/bnr/3001J86020 target=_blank><font color=#FFFF00 size=5 face=\"Geneva, Arial, Helvetica, san-serif\"><strong>GET FREE ACCESS TO XXX PORN!</strong></font></a><br><table width=100 border=3 cellspacing=0 cellpadding=0><tr><td><TABLE WIDTH=550 BORDER=0 CELLPADDING=0 CELLSPACING=0><TR><TD COLSPAN=3><a href=http://www.freepornsecrets.net/bnr/3001J86020 target=_blank><IMG SRC=http://www.freepornsecrets.net/art/freepornsecrets/HC_FPS_01.jpg WIDTH=550 HEIGHT=112 border=0></a></TD></TR><TR><TD><a href=http://www.freepornsecrets.net/bnr/3001J86020 target=_blank><IMG SRC=http://www.freepornsecrets.net/art/freepornsecrets/HC_FPS_02.gif WIDTH=104 HEIGHT=231 border=0></a></TD><TD><a href=http://www.freepornsecrets.net/bnr/3001J86020 target=_blank><IMG SRC=http://www.freepornsecrets.net/art/freepornsecrets/HC_FPS_03.jpg WIDTH=339 HEIGHT!\n",
            " =231 bor ...\n",
            " HYPERLINK GET FREE ACCESS TO XXX PORN! HYPERLINK  HYPERLINK  HYPERLINK  HYPERLINK  HYPERLINK  HYPERLINK INSTANT ACCESS... 100% FREE HARDCORENote: If you would would like to be removed from our list, please reply to this email with the word REMOVE as the subject\n",
            "hxvwnj3q\n",
            " ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generalized function to convert emails to plain text**"
      ],
      "metadata": {
        "id": "Yp609-42tqJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def email_to_text(email):\n",
        "    html = None\n",
        "    for part in email.walk():\n",
        "        ctype = part.get_content_type()\n",
        "        if not ctype in (\"text/plain\", \"text/html\"):\n",
        "            continue\n",
        "        try:\n",
        "            content = part.get_content()\n",
        "        except: # if any encoding issues\n",
        "            content = str(part.get_payload())\n",
        "        if ctype == \"text/plain\":\n",
        "            return content\n",
        "        else:\n",
        "            html = content\n",
        "    if html:\n",
        "        return html_to_plain_text(html)\n",
        "\n",
        "print(email_to_text(sample_html_spam)[:100], \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnobaJXx_dcI",
        "outputId": "c986aaaf-6012-40ed-a738-602654536cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " HYPERLINK GET FREE ACCESS TO XXX PORN! HYPERLINK  HYPERLINK  HYPERLINK  HYPERLINK  HYPERLINK  HYPER ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NLTK for stemming with some examples**"
      ],
      "metadata": {
        "id": "xh8xIVJTuOQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "stemmer = nltk.PorterStemmer()\n",
        "for word in (\"Computations\", \"Computation\", \"Computing\", \"Computed\", \"Compute\", \"Compulsive\"): \n",
        "  print(word, \"=>\", stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccVpGxuI_qOa",
        "outputId": "efab753a-2440-4fa4-e76f-e360ddf49f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computations => comput\n",
            "Computation => comput\n",
            "Computing => comput\n",
            "Computed => comput\n",
            "Compute => comput\n",
            "Compulsive => compuls\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**urlextract to replace URLs with the word \"URL\"**"
      ],
      "metadata": {
        "id": "Ur2E6-ZyvUwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.colab\n",
        "!pip install urlextract\n",
        "\n",
        "import urlextract #Require an Internet connection to download root domain names\n",
        "url_extractor = urlextract.URLExtract()\n",
        "print(url_extractor.find_urls(\"Will it detect github.com and https://youtu.be/7Pq-S557XQU?t=3m32s\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQe7qY_R_5d0",
        "outputId": "a350e64e-d7e4-4524-dfc2-8b4a2fe498ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: urlextract in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from urlextract) (3.6.0)\n",
            "Requirement already satisfied: uritools in /usr/local/lib/python3.7/dist-packages (from urlextract) (4.0.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.7/dist-packages (from urlextract) (2.5.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from urlextract) (2.10)\n",
            "['github.com', 'https://youtu.be/7Pq-S557XQU?t=3m32s']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transformer to convert all the emails to word counter arrays**"
      ],
      "metadata": {
        "id": "t3BUg2kmvrm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, strip_headers=True, lower_case=True, remove_punctuation=True,\n",
        "                 replace_urls=True, replace_numbers=True, stemming=True):\n",
        "        self.strip_headers = strip_headers\n",
        "        self.lower_case = lower_case\n",
        "        self.remove_punctuation = remove_punctuation\n",
        "        self.replace_urls = replace_urls\n",
        "        self.replace_numbers = replace_numbers\n",
        "        self.stemming = stemming\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        X_transformed = []\n",
        "        for email in X:\n",
        "            text = email_to_text(email) or \"\"\n",
        "            if self.lower_case:\n",
        "                text = text.lower()\n",
        "            if self.replace_urls and url_extractor is not None:\n",
        "                urls = list(set(url_extractor.find_urls(text)))\n",
        "                urls.sort(key=lambda url: len(url), reverse=True)\n",
        "                for url in urls:\n",
        "                    text = text.replace(url, \" URL \")\n",
        "            if self.replace_numbers:\n",
        "                text = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', 'NUMBER', text)\n",
        "            if self.remove_punctuation:\n",
        "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
        "            word_counts = Counter(text.split())\n",
        "            if self.stemming and stemmer is not None:\n",
        "                stemmed_word_counts = Counter()\n",
        "                for word, count in word_counts.items():\n",
        "                    stemmed_word = stemmer.stem(word)\n",
        "                    stemmed_word_counts[stemmed_word] += count\n",
        "                word_counts = stemmed_word_counts\n",
        "            X_transformed.append(word_counts)\n",
        "        return np.array(X_transformed)\n",
        "\n",
        "\n",
        "X_few = X_train[:4] #testing 4 examples\n",
        "X_few_wordcounts = EmailToWordCounterTransformer().fit_transform(X_few)\n",
        "X_few_wordcounts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcGtgBSZAFnS",
        "outputId": "a9aa5b6d-2796-44f4-9301-b9e6fb466340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([Counter({'number': 6, 'is': 3, 'the': 3, 'list': 3, 'liblit': 2, 'if': 2, 'font': 2, 'ugli': 2, 'of': 2, 'are': 2, 'gnomenumb': 2, 'for': 2, 'rpm': 2, 'on': 1, 'fri': 1, 'oct': 1, 'ben': 1, 'eec': 1, 'berkeley': 1, 'edu': 1, 'wrote': 1, 'so': 1, 'your': 1, 'look': 1, 'lack': 1, 'bytecod': 1, 'hint': 1, 'not': 1, 'caus': 1, 'well': 1, 'you': 1, 'right': 1, 'sorri': 1, 'i': 1, 'didn': 1, 't': 1, 'have': 1, 'ani': 1, 'better': 1, 'idea': 1, 'yesterday': 1, 'late': 1, 'in': 1, 'even': 1, 'onli': 1, 'insid': 1, 'and': 1, 'clean': 1, 'app': 1, 'antialias': 1, 'disabl': 1, 'thi': 1, 'difficult': 1, 'to': 1, 'understand': 1, 'me': 1, 'regard': 1, 'from': 1, 'germani': 1, 'matthia': 1, '_______________________________________________': 1, 'mail': 1, 'freshrpm': 1, 'net': 1, 'url': 1}),\n",
              "       Counter({'i': 10, 'the': 7, 'a': 6, 'in': 5, 'to': 4, 'like': 3, 'get': 3, 'work': 3, 'number': 3, 'that': 3, 's': 3, 'thi': 3, 'it': 3, 'with': 3, 't': 3, 'tag': 3, 'url': 2, 'we': 2, 'of': 2, 'issu': 2, 'tomorrow': 2, 'too': 2, 'us': 2, 'report': 2, 'if': 2, 'think': 2, 'razor': 2, 'don': 2, 'system': 2, 'on': 2, 'version': 2, 'rel': 2, 'craig': 1, 'said': 1, 'seem': 1, 'good': 1, 'idea': 1, 'might': 1, 'one': 1, 'two': 1, 'other': 1, 'rais': 1, 'onc': 1, 'peopl': 1, 'back': 1, 'and': 1, 'start': 1, 'download': 1, 'earnest': 1, 'yep': 1, 'reckon': 1, 'btw': 1, 'm': 1, 'hear': 1, 'about': 1, 'problem': 1, 'resolv': 1, 'anyon': 1, 'els': 1, 'notic': 1, 'seriou': 1, 'll': 1, 'see': 1, 'can': 1, 'mark': 1, 'reynold': 1, 'add': 1, 'numberndari': 1, 'go': 1, 'primari': 1, 'oz': 1, 'look': 1, 'there': 1, 'may': 1, 'be': 1, 'razornumb': 1, 'is': 1, 'bug': 1, 'glitch': 1, 'trigger': 1, 'when': 1, 'file': 1, 'permiss': 1, 'allow': 1, 'own': 1, 'log': 1, 'at': 1, 'least': 1, 'heard': 1, 'list': 1, 'past': 1, 'theo': 1, 'doe': 1, 'now': 1, 'you': 1, 'dev': 1, 'null': 1, 'd': 1, 'logfil': 1, 'say': 1, 'cv': 1, 'tree': 1, 'as': 1, 'time': 1, 'won': 1, 'bother': 1, 'imo': 1, 'should': 1, 'reli': 1, 'control': 1, 'insid': 1, 'our': 1, 'code': 1, 'so': 1, 've': 1, 'just': 1, 'put': 1, 'line': 1, 'mail': 1, 'spamassassin': 1, 'pm': 1, 'instead': 1, 'will': 1, 'cours': 1, 'releas': 1, 'label': 1, 'though': 1, 'j': 1}),\n",
              "       Counter({'hyperlink': 7, 'to': 3, 'free': 2, 'access': 2, 'would': 2, 'remov': 2, 'the': 2, 'get': 1, 'xxx': 1, 'porn': 1, 'instant': 1, 'number': 1, 'hardcorenot': 1, 'if': 1, 'you': 1, 'like': 1, 'be': 1, 'from': 1, 'our': 1, 'list': 1, 'pleas': 1, 'repli': 1, 'thi': 1, 'email': 1, 'with': 1, 'word': 1, 'as': 1, 'subject': 1, 'hxvwnjnumberq': 1}),\n",
              "       Counter({'list': 6, 'you': 6, 'the': 5, 'number': 4, 'to': 3, 'can': 3, 'rpm': 3, 'url': 3, 'task': 3, 'apt': 3, 'time': 2, 'variou': 2, 'now': 2, 'i': 2, 'do': 2, 'it': 2, 'your': 2, 'sourc': 2, 'get': 2, 'with': 2, 'these': 2, 'are': 2, 'gener': 2, 'of': 2, 'rhnumber': 2, 'they': 2, 'contain': 2, 'packag': 2, 'as': 2, 'll': 2, 'by': 2, 'hi': 1, 'thi': 1, 'ha': 1, 'been': 1, 'hash': 1, 'over': 1, 'a': 1, 'few': 1, 'on': 1, 'final': 1, 'got': 1, 'around': 1, 'someth': 1, 'about': 1, 'add': 1, 'redhat': 1, 'and': 1, 'after': 1, 'updat': 1, 'find': 1, 'out': 1, 'what': 1, 's': 1, 'avail': 1, 'cach': 1, 'search': 1, 'directli': 1, 'from': 1, 'comp': 1, 'xml': 1, 'so': 1, 'exactli': 1, 'same': 1, 'choos': 1, 'categori': 1, 'at': 1, 'instal': 1, 'didn': 1, 't': 1, 'bother': 1, 'includ': 1, 'srpm': 1, 'for': 1, 'rather': 1, 'uninterest': 1, 'if': 1, 'want': 1, 're': 1, 'spec': 1, 'run': 1, 'btw': 1, 'repositori': 1, 'onli': 1, 'need': 1, 'an': 1, 'enabl': 1, 'mirror': 1, 'in': 1, 'actual': 1, 'anyth': 1, 'panu': 1, '_______________________________________________': 1, 'mail': 1, 'freshrpm': 1, 'net': 1})],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Most models prefer numerical inputs, hence converting to vector**"
      ],
      "metadata": {
        "id": "8C3IGiU8xC46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, vocabulary_size=1000):\n",
        "        self.vocabulary_size = vocabulary_size\n",
        "    def fit(self, X, y=None):\n",
        "        total_count = Counter()\n",
        "        for word_count in X:\n",
        "            for word, count in word_count.items():\n",
        "                total_count[word] = total_count[word]+min(count, 10)\n",
        "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
        "        self.most_common_ = most_common\n",
        "        self.vocabulary_ = {word: index + 1 for index, (word, count) in enumerate(most_common)}\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        rows = []\n",
        "        cols = []\n",
        "        data = []\n",
        "        for row, word_count in enumerate(X):\n",
        "            for word, count in word_count.items():\n",
        "                rows.append(row)\n",
        "                cols.append(self.vocabulary_.get(word, 0))\n",
        "                data.append(count)\n",
        "        return csr_matrix((data, (rows, cols)), shape=(len(X), self.vocabulary_size + 1))\n",
        "\n",
        "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size=10)\n",
        "X_few_vectors = vocab_transformer.fit_transform(X_few_wordcounts)\n",
        "X_few_vectors\n",
        "\n",
        "X_few_vectors.toarray()\n",
        "\n",
        "vocab_transformer.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Bt0-gFFANi4",
        "outputId": "8e07ee22-9e0a-4065-d5ed-8e034250f625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': 8,\n",
              " 'hyperlink': 9,\n",
              " 'i': 3,\n",
              " 'if': 10,\n",
              " 'in': 7,\n",
              " 'list': 5,\n",
              " 'number': 2,\n",
              " 'the': 1,\n",
              " 'to': 4,\n",
              " 'you': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t=X_few_vectors.toarray() #example of an output sparse matrix\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L9JfKHvDrhL",
        "outputId": "4e99bbc3-d630-4b61-9e16-df9ce5390ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 67,   3,   6,   1,   1,   3,   1,   1,   0,   0,   2],\n",
              "       [154,   7,   3,  10,   4,   1,   1,   5,   6,   0,   2],\n",
              "       [ 26,   2,   1,   0,   3,   1,   1,   0,   0,   7,   1],\n",
              "       [117,   5,   4,   2,   3,   6,   6,   1,   1,   0,   1]],\n",
              "      dtype=int64)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Making a pipeline for all the preprocessing (emails to wordcounters and subsequently, wordcounter to vectors)**"
      ],
      "metadata": {
        "id": "HhcAM0sCxiwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "preprocess_pipeline = Pipeline([\n",
        "    (\"email_to_wordcount\", EmailToWordCounterTransformer()),\n",
        "    (\"wordcount_to_vector\", WordCounterToVectorTransformer()),])\n",
        "X_train_transformed = preprocess_pipeline.fit_transform(X_train)\n",
        "type(X_train_transformed)"
      ],
      "metadata": {
        "id": "ab0XHPORAWLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6073230-1df0-4941-da46-f80939ddda5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_transformed.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FckWcZqDz2gs",
        "outputId": "5fa51154-38e8-46be-9a09-e8b126607da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2100, 1001)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**converting sparse matrix to array for training**"
      ],
      "metadata": {
        "id": "Q0xivCk6yX_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_conv=X_train_transformed.toarray()\n",
        "print(X_train_conv.shape,y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CGakuCAEY7Y",
        "outputId": "5f640dd4-9fc0-47e2-d856-928fe27586a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2100, 1001) (2100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_conv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huU4wyA6qysO",
        "outputId": "e8a0046a-c147-45b6-dd78-e0aed3e2219a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[22,  6,  3, ...,  0,  0,  0],\n",
              "       [30,  3,  7, ...,  0,  0,  0],\n",
              "       [ 5,  1,  2, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [ 7,  3,  3, ...,  0,  0,  0],\n",
              "       [13,  5,  4, ...,  0,  0,  0],\n",
              "       [71, 23,  8, ...,  0,  0,  0]], dtype=int64)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training an artificial neural network**"
      ],
      "metadata": {
        "id": "S88rDqEk2BjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "model = Sequential()\n",
        "model.add(Dense(units=2100, \n",
        "                input_shape =(1001,), # The input for each sample if matrix of size (dim1, dim2)\n",
        "                activation='relu'))\n",
        "model.add(Dense(units=1024, activation='relu'))\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dense(units=256, activation='relu'))\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dense(units=16, activation='relu'))\n",
        "model.add(Dense(units=8, activation='relu'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YIbrA57VRqp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_conv,y_train,batch_size=32,epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZU2o19DdgoH",
        "outputId": "d4d38d4c-bb31-4470-9915-f12d0b9d36aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "66/66 [==============================] - 4s 51ms/step - loss: 0.6165 - accuracy: 0.8314\n",
            "Epoch 2/5\n",
            "66/66 [==============================] - 3s 50ms/step - loss: 0.1941 - accuracy: 0.8329\n",
            "Epoch 3/5\n",
            "66/66 [==============================] - 3s 50ms/step - loss: 0.2064 - accuracy: 0.9714\n",
            "Epoch 4/5\n",
            "66/66 [==============================] - 3s 50ms/step - loss: 0.1883 - accuracy: 0.9090\n",
            "Epoch 5/5\n",
            "66/66 [==============================] - 3s 50ms/step - loss: 0.1178 - accuracy: 0.9919\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f66bd02f350>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_transformed = preprocess_pipeline.fit_transform(X_test)\n",
        "X_test_conv=X_test_transformed.toarray()"
      ],
      "metadata": {
        "id": "1BB1LKTHicEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test_conv.shape,y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYS6CG7am3gS",
        "outputId": "5b8a1ad1-6520-4463-a698-c7e2997a2032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(900, 1001) (900,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANN achieved a testing accuracy of 83.78%**"
      ],
      "metadata": {
        "id": "nd7o4xMs2NZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import argmax\n",
        "from sklearn.metrics import accuracy_score\n",
        "yhat = model.predict(X_test_conv)\n",
        "yhat = argmax(yhat, axis=-1)\n",
        "acc = accuracy_score(y_test, yhat)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJH8cZjQhRAt",
        "outputId": "030fc490-7914-4334-8ec6-042b2889194d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8377777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "print(\"The precision is \", precision_score(y_test, yhat, average='weighted'))\n",
        "print(\"The recall is \", recall_score(y_test, yhat, average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKB92EMt16e5",
        "outputId": "0700e11d-6b39-427a-b9e5-b2df5eb94b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The precision is  0.7018716049382716\n",
            "The recall is  0.8377777777777777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}